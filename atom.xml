<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>追书吧</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.bookmounting.com/"/>
  <updated>2019-12-27T01:14:16.173Z</updated>
  <id>http://www.bookmounting.com/</id>
  
  <author>
    <name>oyzq</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>[转]高并发性能调试经验分享</title>
    <link href="http://www.bookmounting.com/27/%E8%BD%AC-%E9%AB%98%E5%B9%B6%E5%8F%91%E6%80%A7%E8%83%BD%E8%B0%83%E8%AF%95%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB/"/>
    <id>http://www.bookmounting.com/27/转-高并发性能调试经验分享/</id>
    <published>2019-12-27T01:11:45.000Z</published>
    <updated>2019-12-27T01:14:16.173Z</updated>
    
    <content type="html"><![CDATA[<p>作者：helloworlds</p><h2 id="引文"><a href="#引文" class="headerlink" title="引文"></a>引文</h2><p>4月份的时候看到一道面试题，据说是腾讯校招面试官提的：在多线程和高并发环境下，如果有一个平均运行一百万次才出现一次的bug，你如何调试这个bug？知乎原贴地址如下：<a href="https://www.zhihu.com/question/43416744" target="_blank" rel="noopener">腾讯实习生面试，这两道题目该怎么回答？ - 编程</a> .<br>遗憾的是知乎很多答案在抨击这道题本身的正确性，虽然我不是这次的面试官，但我认为这是一道非常好的面试题。当然，只是道加分题，答不上，不扣分。答得不错，说明解决问题的思路和能力要超过应届生平均水平。<br>之所以写上面这段，是因为我觉得大部分后台服务端开发都有可能遇到这样的BUG，即使没有遇到，这样的题目也能够激发大家不断思考和总结。非常凑巧的是，我在4月份也遇到了一个类似的而且要更加严重的BUG，这是我自己挖的一个很深的坑，不填好，整个项目就无法上线。<br>现在已经过去了一个多月，趁着有时间，自己好好总结一下，希望里面提到的一些经验和工具能够带给大家一点帮助。</p><h2 id="项目背景"><a href="#项目背景" class="headerlink" title="项目背景"></a>项目背景</h2><p>我们针对nginx事件框架和openssl协议栈进行了一些深度改造，以提升nginx的HTTPS完全握手计算性能。<br>由于原生nginx使用本地CPU做RSA计算，ECDHE_RSA算法的单核处理能力只有400 qps左右。前期测试时的并发性能很低，就算开了24核，性能也无法超过1万。<br>核心功能在去年底就完成了开发，线下测试也没有发现问题。经过优化后的性能提升几倍，为了测试最大性能，使用了很多客户端并发测试https性能。很快就遇到了一些问题：</p><ol><li>第一个问题是nginx有极低概率（亿分之一）在不同地方 core dump。白天线下压力测试2W qps一般都要两三个小时才出一次core。每次晚上睡觉之前都会将最新的调试代码编译好并启动测试，到早上醒来第一眼就会去查看机器并祈祷不要出core，不幸的是，一般都会有几个到几十个core，并且会发现经常是在一个时间点集中core dump。线上灰度测试运行了6天，在第6天的早上才集中core dump了几十次。这样算来，这个core dump的概率至少是亿分之一了。 不过和面试题目中多线程不同的是，nginx采用的是多进程+全异步事件驱动的编程模式（目前也支持了多线程，但只是针对IO的优化，核心机制还是多进程加异步）。在webserver的实现背景下，多进程异步相比多线程的优点是性能高，没有太多线程间的切换，而且内存空间独立，省去线程间锁的竞争。当然也有缺点，就是异步模式编程非常复杂，将一些逻辑上连续的事件从空间和时间切割，不符合人的正常思考习惯，出了问题后比较难追查。另外异步事件对网络和操作系统的底层知识要求较高，稍不小心就容易挖坑。</li><li>第二个问题是高并发时nginx存在内存泄漏。在流量低的时候没有问题，加大测试流量就会出现内存泄漏。</li><li>第三个问题，因为我们对nginx和openssl的关键代码都做了一些改造，希望提升它的性能。那么如何找到性能热点和瓶颈并持续优化呢？</li></ol><p><strong>其中第一和第二个问题的背景都是，只有并发上万qps以上时才有可能出现，几百或者一两千QPS时，程序没有任何问题。</strong></p><h2 id="core-dump的调试"><a href="#core-dump的调试" class="headerlink" title="core dump的调试"></a>core dump的调试</h2><p>首先说一下core的解决思路，主要是如下几点：</p><ol><li>gdb及debug log定位，发现作用不大。</li><li>如何重现bug？</li><li>构造高并发压力测试系统。</li><li>构造稳定的异常请求。</li></ol><h2 id="gdb及debug-log效率太低"><a href="#gdb及debug-log效率太低" class="headerlink" title="gdb及debug log效率太低"></a>gdb及debug log效率太低</h2><p>因为有core dump ，所以这个问题初看很容易定位。gdb 找到core dump点，btrace就能知道基本的原因和上下文了。<br>core的直接原因非常简单和常见，<strong>全部都是NULL指针引用导致的</strong>。不过从函数上下文想不通为什么会出现NULL值，因为这些指针在原生nginx的事件和模块中都是这么使用的，不应该在这些地方变成NULL。由于暂时找不到根本原因，还是先解决CORE dump吧，修复办法也非常简单，直接判断指针是否NULL，如果是NULL就直接返回，不引用不就完事了，这个地方以后肯定不会出CORE了。</p><blockquote><p>这样的防守式编程并不提倡，指针NULL引用如果不core dump，而是直接返回，那么这个错误很有可能会影响用户的访问，同时这样的BUG还不知道什么时候能暴露。所以CORE DUMP 在NULL处，其实是非常负责任和有效的做法。</p></blockquote><p>在NULL处返回，确实避免了在这个地方的CORE，但是过几个小时又core 在了另外一个NULL指针引用上。于是我又继续加个判断并避免NULL指针的引用。悲剧的是，过了几个小时，又CORE在了其他地方，就这样过了几天，我一直在想为什么会出现一些指针为NULL的情况？为什么会CORE在不同地方？为什么我用浏览器和curl这样的命令工具访问却没有任何问题？</p><blockquote><p>熟悉nginx代码的同学应该很清楚，nginx极少在函数入口及其他地方判断指针是否为NULL值。特别是一些关键数据结构，比如‘ngx_connection_t’及SSL_CTX等，在请求接收的时候就完成了初始化，所以不可能在后续正常处理过程中出现NULL的情况。</p></blockquote><p>于是我更加迷惑，显然NULL值导致出CORE只是表象，真正的问题是，这些关键指针为什么会被赋值成NULL？<br>这个时候异步事件编程的缺点和复杂性就暴露了，好好的一个客户端的请求，从逻辑上应该是连续的，但是被读写及时间事件拆成了多个片断。虽然GDB能准确地记录core dump时的函数调用栈，但是却无法准确记录一条请求完整的事件处理栈。根本就不知道上次是哪个事件的哪些函数将这个指针赋值为NULL的,甚至都不知道这些数据结构上次被哪个事件使用了。</p><blockquote><p>举个例子：客户端发送一个正常的get请求，由于网络或者客户端行为，需要发送两次才完成。服务端第一次read没有读取完全部数据，这次读事件中调用了 A，B函数，然后事件返回。第二次数据来临时，再次触发read事件，调用了A，C函数。并且core dump在了C函数中。这个时候，btrace的stack frame已经没有B函数调用的信息了。</p></blockquote><p>所以<strong>通过GDB无法准确定位 core 的真正原因</strong></p><p><strong>log debug的新尝试</strong><br>这时候强大的GDB已经派不上用场了。怎么办？打印nginx调试日志。<br>但是打印日志也很郁闷，只要将nginx的日志级别调整到DEBUG，CORE就无法重现。为什么？因为DEBUG的日志信息量非常大，频繁地写磁盘严重影响了NGINX的性能，打开DEBUG后性能由几十万直线下降到几百qps。<br>调整到其他级别比如 INFO,性能虽然好了，但是日志信息量太少，没有帮助。尽管如此，日志却是个很好的工具，于是又尝试过以下办法：</p><ol><li>针对特定客户端IP开启debug日志，比如IP是10.1.1.1就打印DEBUG，其他IP就打印最高级别的日志，nginx本身就支持这样的配置。</li><li>关闭DEBUG日志，自己在一些关键路径添加高级别的调试日志，将调试信息通过EMERG级别打印出来。</li><li>nginx只开启一个进程和少量的connection数。抽样打印连接编号（比如尾号是1）的调试日志。</li></ol><p>总体思路依然是在不明显降低性能的前提下打印尽量详细的调试日志，遗憾的是，上述办法还是不能帮助问题定位，当然了，在不断的日志调试中，对代码和逻辑越来越熟悉。</p><h2 id="bug如何重现？"><a href="#bug如何重现？" class="headerlink" title="bug如何重现？"></a>bug如何重现？</h2><p>这时候的调试效率已经很低了，几万QPS连续压力测试，几个小时才出一次CORE，然后修改代码，添加调试日志。几天过去了，毫无进展。所以必须要在线下构造出稳定的core dump环境，这样才能加快debug效率。<br>虽然还没有发现根本原因，但是发现了一个很可疑的地方：<br><strong>出CORE比较集中，经常是在凌晨4,5点，早上7,8点的时候 dump几十个CORE。</strong></p><h2 id="弱网络环境的构造-traffic-control"><a href="#弱网络环境的构造-traffic-control" class="headerlink" title="弱网络环境的构造 traffic control"></a>弱网络环境的构造 traffic control</h2><p>联想到夜间有很多的网络硬件调整及故障，我猜测这些core dump可能跟网络质量相关。<strong>特别是网络瞬时不稳定，很容易触发BUG导致大量的CORE DUMP。</strong><br>最开始我考虑过使用TC(traffic control)工具来构造弱网络环境，但是转念一想，弱网络环境导致的结果是什么？显然是网络请求的各种异常啊,所以还不如直接构造各种异常请求来复现问题。于是准备构造测试工具和环境，需要满足两个条件：</p><ol><li>并发性能强，能够同时发送数万甚至数十万级以上qps。</li><li>请求需要一定概率的异常。特别是TCP握手及SSL握手阶段，需要异常中止。</li></ol><blockquote><p><strong>traffic control是一个很好的构造弱网络环境的工具</strong>，我之前用过测试SPDY协议性能。能够控制网络速率、丢包率、延时等网络环境，作为iproute工具集中的一个工具，由linux系统自带。但比较麻烦的是TC的配置规则很复杂，facebook在tc的基础上封装成了一个开源工具<a href="https://link.zhihu.com/?target=https%3A//github.com/facebook/augmented-traffic-control" target="_blank" rel="noopener">apc</a>，有兴趣的可以试试。</p></blockquote><h2 id="WRK压力测试工具"><a href="#WRK压力测试工具" class="headerlink" title="WRK压力测试工具"></a>WRK压力测试工具</h2><p>由于高并发流量时才可能出core，所以首先就需要找一个性能强大的压测工具。<br><a href="https://link.zhihu.com/?target=https%3A//github.com/wg/wrk" target="_blank" rel="noopener">WRK</a>是一款非常优秀的开源HTTP压力测试工具，采用多线程 + 异步事件驱动的框架，其中事件机制使用了redis的ae事件框架，协议解析使用了nginx的相关代码。<br>相比ab（apache bench）等传统压力测试工具的优点就是性能好，基本上单台机器发送几百万pqs,打满网卡都没有问题。<br>wrk的缺点就是只支持HTTP类协议，不支持其他协议类测试，比如protobuf，另外数据显示也不是很方便。</p><blockquote><p>nginx的测试用法： wrk -t500 -c2000 -d30s <a href="https://link.zhihu.com/?target=https%3A//127.0.0.1%3A8443/index.html" target="_blank" rel="noopener">https://127.0.0.1:8443/index.html</a></p></blockquote><h2 id="分布式自动测试系统的构建"><a href="#分布式自动测试系统的构建" class="headerlink" title="分布式自动测试系统的构建"></a>分布式自动测试系统的构建</h2><p>由于是HTTPS请求，使用ECDHE_RSA密钥交换算法时，客户端的计算消耗也比较大，单机也就10000多qps。也就是说如果server的性能有3W qps，那么一台客户端是无法发送这么大的压力的，所以需要构建一个多机的分布式测试系统，即通过中控机同时控制多台测试机客户端启动和停止测试。<br>之前也提到了，调试效率太低，整个测试过程需要能够自动化运行，比如晚上睡觉前，可以控制多台机器在不同的协议，不同的端口，不同的cipher suite运行整个晚上。白天因为一直在盯着，运行几分钟就需要查看结果。<br>这个系统有如下功能：<br>\1. 并发控制多台测试客户端的启停，最后汇总输出总的测试结果。<br>\2. 支持https，http协议测试，支持webserver及revers proxy性能测试。<br>\3. 支持配置不同的测试时间、端口、URL。<br>\4. 根据端口选择不同的SSL协议版本，不同的cipher suite。<br>\5. 根据URL选择webserver、revers proxy模式。</p><h2 id="异常测试请求的构造"><a href="#异常测试请求的构造" class="headerlink" title="异常测试请求的构造"></a>异常测试请求的构造</h2><p>压力测试工具和系统都准备好了，还是不能准确复现core dump的环境。接下来还要完成异常请求的构造。构造哪些异常请求呢？<br>由于新增的功能代码主要是和SSL握手相关，这个过程是紧接着TCP握手发生的，所以异常也主要发生在这个阶段。于是我考虑构造了如下三种异常情形：</p><ol><li>异常的tcp连接。即在客户端tcp connent系统调用时，10%概率直接close这个socket。</li><li>异常的ssl连接。考虑两种情况，full handshake第一阶段时，即发送 client hello时，客户端10%概率直接close连接。full handshake第二阶段时，即发送clientKeyExchange时，客户端10%概率直接直接关闭TCP连接。</li><li>异常的HTTPS请求，客户端10%的请求使用错误的公钥加密数据，这样nginx解密时肯定会失败。</li></ol><h2 id="core-bug-fix小结"><a href="#core-bug-fix小结" class="headerlink" title="core bug fix小结"></a>core bug fix小结</h2><p>构造好了上述高并发压力异常测试系统，果然，几秒钟之内必然出CORE。有了稳定的测试环境，那bug fix的效率自然就会快很多。<br>虽然此时通过gdb还是不方便定位根本原因，但是测试请求已经满足了触发CORE的条件，打开debug调试日志也能触发core dump。于是可以不断地修改代码，不断地GDB调试，不断地增加日志，一步步地追踪根源，一步步地接近真相。<br>最终通过不断地重复上述步骤找到了core dump的根本原因。其实在写总结文档的时候，core dump的根本原因是什么已经不太重要，最重要的还是解决问题的思路和过程，这才是值得分享和总结的。很多情况下，千辛万苦排查出来的，其实是一个非常明显甚至愚蠢的错误。<br>比如这次core dump的主要原因是：<br>由于没有正确地设置non-reusable，并发量太大时，用于异步代理计算的connection结构体被nginx回收并进行了初始化，从而导致不同的事件中出现NULL指针并出CORE。</p><h2 id="内存泄漏"><a href="#内存泄漏" class="headerlink" title="内存泄漏"></a>内存泄漏</h2><p>虽然解决了core dump，但是另外一个问题又浮出了水面，就是<strong>高并发测试时，会出现内存泄漏，大概一个小时500M的样子</strong>。</p><h2 id="valgrind的缺点"><a href="#valgrind的缺点" class="headerlink" title="valgrind的缺点"></a>valgrind的缺点</h2><p>出现内存泄漏或者内存问题，大家第一时间都会想到<a href="https://link.zhihu.com/?target=http%3A//valgrind.org/" target="_blank" rel="noopener">valgrind</a><br>valgrind是一款非常优秀的软件，不需要重新编译程序就能够直接测试。功能也非常强大，能够检测常见的内存错误包括内存初始化、越界访问、内存溢出、free错误等都能够检测出来。推荐大家使用。<br>valgrind 运行的基本原理是：<br><strong>待测程序运行在valgrind提供的模拟CPU上，valgrind会纪录内存访问及计算值，最后进行比较和错误输出</strong><br>我通过valgrind测试nginx也发现了一些内存方面的错误，简单分享下valgrind测试nginx的经验：</p><ol><li>nginx通常都是使用master fork子进程的方式运行，使用–trace-children=yes来追踪子进程的信息</li><li>测试nginx + openssl时，在使用rand函数的地方会提示很多内存错误。比如Conditional jump or move depends on uninitialised value，Uninitialised value was created by a heap allocation等。这是由于rand数据需要一些熵，未初始化是正常的。如果需要去掉valgrind提示错误，编译时需要加一个选项：<strong>-DPURIFY</strong></li><li>如果nginx进程较多，比如超过4个时，会导致valgrind的错误日志打印混乱，尽量减小nginx工作进程,保持为1个。因为一般的内存错误其实和进程数目都是没有关系的。</li></ol><p>上面说了valgrind的功能和使用经验，但是valgrind也有一个非常大的缺点，<strong>就是它会显著降低程序的性能，官方文档说使用memcheck工具时，降低10-50倍</strong><br>也就是说，如果nginx完全握手性能是20000 qps,那么使用valgrind测试，性能就只有400 qps左右。对于一般的内存问题，降低性能没啥影响，但是我这次的内存泄漏是在大压力测试时才可能遇到的，<strong>如果性能降低这么明显，内存泄漏的错误根本检测不出来。</strong><br>只能再考虑其他办法了。</p><h2 id="AddressSanitizer的优点"><a href="#AddressSanitizer的优点" class="headerlink" title="AddressSanitizer的优点"></a>AddressSanitizer的优点</h2><p>address sanitizer（简称asan）是一个用来检测c/c++程序的快速内存检测工具。相比valgrind的优点就是速度快，<a href="https://link.zhihu.com/?target=https%3A//github.com/google/sanitizers/wiki/" target="_blank" rel="noopener">官方文档</a>介绍对程序性能的降低只有2倍。<br>对Asan原理有兴趣的同学可以参考<a href="https://cppfans.org/(https://github.com/google/sanitizers/wiki/AddressSanitizerAlgorithm" target="_blank" rel="noopener">asan的算法</a>这篇文章，它的实现原理就是在程序代码中插入一些自定义代码，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> 编译前：  </span><br><span class="line">*address = ...;  //   or: ... = *address; </span><br><span class="line">编译后：   </span><br><span class="line">if (IsPoisoned(address)) &#123; </span><br><span class="line">    ReportError(address, kAccessSize, kIsWrite);  </span><br><span class="line">&#125;</span><br><span class="line">*address = ...;  // or: ... = *address;`</span><br></pre></td></tr></table></figure><p>和valgrind明显不同的是，asan需要添加编译开关重新编译程序，好在不需要自己修改代码。而valgrind不需要编程程序就能直接运行。<br>address sanitizer集成在了clang编译器中，GCC 4.8版本以上才支持。我们线上程序默认都是使用gcc4.3编译，于是我测试时直接使用clang重新编译nginx：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">–with-cc=“clang” \</span><br><span class="line">–with-cc-opt=“-g -fPIC -fsanitize=address -fno-omit-frame-pointer”</span><br><span class="line">其中with-cc是指定编译器，with-cc-opt指定编译选项， -fsanitize=address就是开启AddressSanitizer功能。</span><br></pre></td></tr></table></figure><p>由于AddressSanitizer对nginx的影响较小，所以大压力测试时也能达到上万的并发，内存泄漏的问题很容易就定位了。<br>这里就不详细介绍内存泄漏的原因了，因为跟openssl的错误处理逻辑有关，是我自己实现的，没有普遍的参考意义。<br><strong>最重要的是，知道valgrind和asan的使用场景和方法，遇到内存方面的问题能够快速修复。</strong></p><h2 id="性能热点分析"><a href="#性能热点分析" class="headerlink" title="性能热点分析"></a>性能热点分析</h2><p>到此，经过改造的nginx程序没有core dump和内存泄漏方面的风险了。但这显然不是我们最关心的结果（因为代码本该如此），我们最关心的问题是：<br>\1. 代码优化前，程序的瓶颈在哪里？能够优化到什么程度？<br>\2. 代码优化后，优化是否彻底？会出现哪些新的性能热点和瓶颈？<br>这个时候我们就需要一些工具来检测程序的性能热点。</p><h2 id="perf，oprofile，gprof，systemtap"><a href="#perf，oprofile，gprof，systemtap" class="headerlink" title="perf，oprofile，gprof，systemtap"></a>perf，oprofile，gprof，systemtap</h2><p>linux世界有许多非常好用的性能分析工具，我挑选几款最常用的简单介绍下：<br>\1. [perf](<a href="https://cppfans.org/a" target="_blank" rel="noopener">https://cppfans.org/a</a> class=” wrap external” href=”<a href="https://link.zhihu.com/?target=https%3A//perf.wiki.kernel.org/index.php/Main_Page&quot;" target="_blank" rel="noopener">https://link.zhihu.com/?target=https%3A//perf.wiki.kernel.org/index.php/Main_Page&quot;</a> target=”_blank” rel=”nofollow noreferrer” rel=”nofollow” &gt;Perf Wiki应该是最全面最方便的一个性能检测工具。由linux内核携带并且同步更新，基本能满足日常使用。<strong>推荐大家使用</strong>。<br>\2. <a href="https://link.zhihu.com/?target=http%3A//oprofile.sourceforge.net/news/" target="_blank" rel="noopener">oprofile</a>，我觉得是一个较过时的性能检测工具了，基本被perf取代，命令使用起来也不太方便。比如opcontrol –no-vmlinux , opcontrol –init等命令启动，然后是opcontrol –start， opcontrol –dump， opcontrol -h停止，opreport查看结果等，一大串命令和参数。有时候使用还容易忘记初始化，数据就是空的。<br>\3. <a href="https://link.zhihu.com/?target=https%3A//sourceware.org/binutils/docs/gprof/" target="_blank" rel="noopener">gprof</a>主要是针对应用层程序的性能分析工具，缺点是需要重新编译程序，而且对程序性能有一些影响。不支持内核层面的一些统计，优点就是应用层的函数性能统计比较精细，接近我们对日常性能的理解，比如各个函数时间的运行时间，，函数的调用次数等，很人性易读。<br>\4. <a href="https://link.zhihu.com/?target=https%3A//sourceware.org/systemtap/" target="_blank" rel="noopener">systemtap</a> 其实是一个运行时程序或者系统信息采集框架，主要用于动态追踪，当然也能用做性能分析，功能最强大，同时使用也相对复杂。不是一个简单的工具，可以说是一门动态追踪语言。<strong>如果程序出现非常麻烦的性能问题时，推荐使用 systemtap。</strong></p><p>这里再多介绍一下perf命令，linux系统上默认都有安装，比如通过perf top就能列举出当前系统或者进程的热点事件，函数的排序。<br>perf record能够纪录和保存系统或者进程的性能事件，用于后面的分析，比如接下去要介绍的火焰图。</p><h2 id="火焰图-flame-graph"><a href="#火焰图-flame-graph" class="headerlink" title="火焰图 flame graph"></a>火焰图 flame graph</h2><p>perf有一个缺点就是不直观。<a href="https://link.zhihu.com/?target=http%3A//www.brendangregg.com/" target="_blank" rel="noopener">火焰图</a>就是为了解决这个问题。它能够以矢量图形化的方式显示事件热点及函数调用关系。<br>比如我通过如下几条命令就能绘制出原生nginx在ecdhe_rsa cipher suite下的性能热点：</p><ol><li>perf record -F 99 -p PID -g – sleep 10</li><li>perf script | ./stackcollapse-perf.pl &gt; out.perf-folded</li><li>./flamegraph.pl out.perf-folded&gt;ou.svg</li></ol><p><a href="https://pic1.zhimg.com/23a96aa134dfb461dc2843917fa909fc_b.png" target="_blank" rel="noopener"><img src="https://pic1.zhimg.com/23a96aa134dfb461dc2843917fa909fc_r.png" alt="img"></a>直接通过火焰图就能看到各个函数占用的百分比，比如上图就能清楚地知道rsaz_1024_mul_avx2和rsaz_1024_sqr_avx2函数占用了75%的采样比例。那我们要优化的对象也就非常清楚了，能不能避免这两个函数的计算？或者使用非本地CPU方案实现它们的计算？<br>当然是可以的，我们的异步代理计算方案正是为了解决这个问题，<a href="https://pic2.zhimg.com/674adcc40599d21727f5464b3d7f2549_b.png" target="_blank" rel="noopener"><img src="https://pic2.zhimg.com/674adcc40599d21727f5464b3d7f2549_r.png" alt="img"></a>从上图可以看出，热点事件里已经没有RSA相关的计算了。至于是如何做到的，后面有时间再写专门的文章来分享。</p><h2 id="心态"><a href="#心态" class="headerlink" title="心态"></a>心态</h2><p>为了解决上面提到的core dump和内存泄漏问题，花了大概三周左右时间。压力很大，精神高度紧张， 说实话有些狼狈，看似几个很简单的问题，搞了这么长时间。心里当然不是很爽，会有些着急，特别是项目的关键上线期。但即使这样，整个过程我还是非常自信并且斗志昂扬。我一直在告诉自己：</p><ol><li>调试BUG是一次非常难得的学习机会，不要把它看成是负担。不管是线上还是线下，能够主动地，高效地追查BUG特别是有难度的BUG，对自己来说一次非常宝贵的学习机会。面对这么好的学习机会，自然要充满热情，要如饥似渴，回首一看，如果不是因为这个BUG，我也不会对一些工具有更深入地了解和使用，也就不会有这篇文档的产生。</li><li>不管什么样的BUG，随着时间的推移，肯定是能够解决的。这样想想，其实会轻松很多，特别是接手新项目，改造复杂工程时，由于对代码，对业务一开始并不是很熟悉，需要一个过渡期。但关键是，你要把这些问题放在心上。白天上班有很多事情干扰，上下班路上，晚上睡觉前，大脑反而会更加清醒，思路也会更加清晰。特别是白天上班时容易思维定势，陷入一个长时间的误区，在那里调试了半天，结果大脑一片混沌。睡觉前或者上下班路上一个人时，反而能想出一些新的思路和办法。</li><li>开放地讨论。遇到问题不要不好意思，不管多简单，多低级，只要这个问题不是你google一下就能得到的结论，大胆地，认真地和组内同事讨论。这次BUG调试，有几次关键的讨论给了我很大的启发，特别是最后reusable的问题，也是组内同事的讨论才激发了我的灵感。谢谢大家的帮助。</li></ol><p><strong>作者介绍  罗成</strong></p><ul><li>高级研发工程师，现任职于腾讯TEG基础架构部，对HTTPS、SPDY、HTTP2等应用层协议、高性能服务器技术、用户访问速度及运维技术有较深理解。</li><li>曾供职于百度，主导百度安全搜索全站HTTPS的性能优化，作为核心成员实现了百度网盟广告配置文件传输系统及百度早期的持续部署系统。</li></ul><p>文章转载自：<a href="https://zhuanlan.zhihu.com/p/21348220" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/21348220</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;作者：helloworlds&lt;/p&gt;
&lt;h2 id=&quot;引文&quot;&gt;&lt;a href=&quot;#引文&quot; class=&quot;headerlink&quot; title=&quot;引文&quot;&gt;&lt;/a&gt;引文&lt;/h2&gt;&lt;p&gt;4月份的时候看到一道面试题，据说是腾讯校招面试官提的：在多线程和高并发环境下，如果有一个平均运行
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>hexo-useguide</title>
    <link href="http://www.bookmounting.com/25/hexo-useguide-1/"/>
    <id>http://www.bookmounting.com/25/hexo-useguide-1/</id>
    <published>2019-12-25T05:11:23.000Z</published>
    <updated>2019-12-25T05:14:55.373Z</updated>
    
    <content type="html"><![CDATA[<p>hexo new post name</p><p>hexo g -d</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;hexo new post name&lt;/p&gt;
&lt;p&gt;hexo g -d&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>代码优化1</title>
    <link href="http://www.bookmounting.com/25/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%961/"/>
    <id>http://www.bookmounting.com/25/代码优化1/</id>
    <published>2019-12-25T01:37:52.000Z</published>
    <updated>2019-12-25T04:26:21.743Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>数据结构与算法实践1-双向链表</title>
    <link href="http://www.bookmounting.com/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B51-%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8/"/>
    <id>http://www.bookmounting.com/06/数据结构与算法实践1-双向链表/</id>
    <published>2019-08-06T06:01:50.000Z</published>
    <updated>2019-08-06T06:01:50.521Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>3步搞定vnpy</title>
    <link href="http://www.bookmounting.com/26/3%E6%AD%A5%E6%90%9E%E5%AE%9Avnpy/"/>
    <id>http://www.bookmounting.com/26/3步搞定vnpy/</id>
    <published>2019-07-26T00:55:11.000Z</published>
    <updated>2019-07-26T01:25:02.034Z</updated>
    
    <content type="html"><![CDATA[<p><strong>前提</strong></p><p>Anaconda要先安装好，注意选择Python3.7的最新版。</p><p>从github上下载最新的vnpy</p><p><strong>创建vnpy环境</strong></p><p>Anaconda Prompt下进入vnpy所在目录，执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create --name test-vnpy python=3.7</span><br></pre></td></tr></table></figure><p>激活：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate vnpy-test</span><br></pre></td></tr></table></figure><p><strong>编译vnpy</strong></p><p>vnpy提供了一键安装依赖和编译的脚本，在Anaconda Prompt下执行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">install.bat</span><br></pre></td></tr></table></figure><p><strong>安装vnpy-test的Spyder</strong></p><p>打开Anaconda Navigator工具，选择到vnpy-test，安装Spyder。</p><p><strong>测试</strong></p><p>打开Spyder(vnpy-test)，新建Python文件，执行以下代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Created on Fri Jul 26 08:44:53 2019</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: Administrator</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> vnpy.event <span class="keyword">import</span> EventEngine</span><br><span class="line"><span class="keyword">from</span> vnpy.trader.engine <span class="keyword">import</span> MainEngine</span><br><span class="line"><span class="keyword">from</span> vnpy.trader.ui <span class="keyword">import</span> MainWindow, create_qapp</span><br><span class="line"><span class="keyword">from</span> vnpy.gateway.ctp <span class="keyword">import</span> CtpGateway</span><br><span class="line"><span class="keyword">from</span> vnpy.app.cta_strategy <span class="keyword">import</span> CtaStrategyApp</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""Start VN Trader"""</span></span><br><span class="line">    qapp = create_qapp()</span><br><span class="line"></span><br><span class="line">    event_engine = EventEngine()</span><br><span class="line">    main_engine = MainEngine(event_engine)</span><br><span class="line"></span><br><span class="line">    main_engine.add_gateway(CtpGateway)</span><br><span class="line">    main_engine.add_app(CtaStrategyApp)</span><br><span class="line"></span><br><span class="line">    main_window = MainWindow(main_engine, event_engine)</span><br><span class="line">    main_window.showMaximized()</span><br><span class="line"></span><br><span class="line">    qapp.exec()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;前提&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Anaconda要先安装好，注意选择Python3.7的最新版。&lt;/p&gt;
&lt;p&gt;从github上下载最新的vnpy&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;创建vnpy环境&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Anaconda Pro
      
    
    </summary>
    
    
      <category term="vnpy" scheme="http://www.bookmounting.com/tags/vnpy/"/>
    
  </entry>
  
  <entry>
    <title>LockFree-ABA与指令重排问题</title>
    <link href="http://www.bookmounting.com/16/LockFree-ABA%E4%B8%8E%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%E9%97%AE%E9%A2%98/"/>
    <id>http://www.bookmounting.com/16/LockFree-ABA与指令重排问题/</id>
    <published>2019-07-16T00:46:43.000Z</published>
    <updated>2019-07-16T00:50:44.260Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ABA"><a href="#ABA" class="headerlink" title="ABA"></a>ABA</h2><p>在多线程编程中，最常拿来举例的问题便是著名的i++ 问题，即：多个线程对同一个共享变量i执行i++ 操作。这样做之所以会出现问题的原因在于i++这个操作可以分为三个步骤：</p><table><thead><tr><th align="center">step</th><th align="center">operation</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">i-&gt;reg(读取i的值到寄存器)</td></tr><tr><td align="center">2</td><td align="center">inc-reg(在寄存器中自增i的值)</td></tr><tr><td align="center">3</td><td align="center">reg-&gt;i (写回内存中的i)</td></tr></tbody></table><p>上面三个步骤中间是可以间隔的，并非原子操作，也就是说多个线程同时执行的时候可能出步骤的交叉执行，例如下面的情况：</p><table><thead><tr><th align="center">step</th><th align="center">thread A</th><th align="center">thread B</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">i-&gt;reg</td><td align="center"></td></tr><tr><td align="center">2</td><td align="center">inc-reg</td><td align="center"></td></tr><tr><td align="center">3</td><td align="center"></td><td align="center">i-&gt;reg</td></tr><tr><td align="center">4</td><td align="center"></td><td align="center">inc-reg</td></tr><tr><td align="center">5</td><td align="center">reg-&gt;i</td><td align="center"></td></tr><tr><td align="center">6</td><td align="center"></td><td align="center">reg-&gt;i</td></tr></tbody></table><p>假设i一开始为0，则执行完第4步后，在两个线程都认为寄存器中的值为1，然后在第5、6两步分别写回去。最终两个线程执行完成后i的值为1。但是实际上我们在两个线程中执行了i++，原本希望i的值为2。i++ 实际上可以代表多线程编程中由于操作不是原子的而引发的交叉执行这一类的问题，但是在这里我们先只关注对单个变量的操作。</p><h2 id="指令重排"><a href="#指令重排" class="headerlink" title="指令重排"></a>指令重排</h2><p>有时候，我们会用一个变量作为标志位，当这个变量等于某个特定值的时候就进行某些操作。但是这样依然可能会有一些意想不到的坑，例如两个线程以如下顺序执行：</p><table><thead><tr><th align="center">step</th><th align="center">thread A</th><th align="center">thread B</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">a = 1</td><td align="center"></td></tr><tr><td align="center">2</td><td align="center">flag= true</td><td align="center"></td></tr><tr><td align="center">3</td><td align="center"></td><td align="center">if flag== true</td></tr><tr><td align="center">4</td><td align="center"></td><td align="center">assert(a == 1)</td></tr></tbody></table><p>当B判断flag为true后，断言a为1，看起来的确是这样。那么一定是这样吗？可能不是，因为编译器和CPU都可能将指令进行重排（编译器不同等级的优化和CPU的乱序执行）。实际上的执行顺序可能变成这样：</p><table><thead><tr><th align="center">step</th><th align="center">thread A</th><th align="center">thread B</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">flag = true</td><td align="center"></td></tr><tr><td align="center">2</td><td align="center"></td><td align="center">if flag== true</td></tr><tr><td align="center">3</td><td align="center"></td><td align="center">assert(a == 1)</td></tr><tr><td align="center">4</td><td align="center">a = 1</td><td align="center"></td></tr></tbody></table><p>这种重排有可能会导致一个线程内相互之间不存在依赖关系的指令交换执行顺序，以获得更高的执行效率。比如上面：flag 与 a 在A线程看起来是没有任何依赖关系，似乎执行顺序无关紧要。但问题在于B使用了flag作为是否读取a的依据，A的指令重排可能会导致step3的时候断言失败。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>一个比较稳妥的办法就是对于共享变量的访问进行加锁，加锁可以保证对临界区的互斥访问，例如第一种场景如果加锁后再执行i++ 然后解锁，则同一时刻只会有一个线程在执行i++ 操作。另外，加锁的内存语义能保证一个线程在释放锁前的写入操作一定能被之后加锁的线程所见（即有happens before 语义），可以避免第二种场景中读取到错误的值。</p><p>那么如果觉得加锁操作过重太麻烦而不想加锁呢？C++11提供了一些原子变量与原子操作来支持。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;ABA&quot;&gt;&lt;a href=&quot;#ABA&quot; class=&quot;headerlink&quot; title=&quot;ABA&quot;&gt;&lt;/a&gt;ABA&lt;/h2&gt;&lt;p&gt;在多线程编程中，最常拿来举例的问题便是著名的i++ 问题，即：多个线程对同一个共享变量i执行i++ 操作。这样做之所以会出现问题的原
      
    
    </summary>
    
    
      <category term="C++" scheme="http://www.bookmounting.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>功夫安装</title>
    <link href="http://www.bookmounting.com/15/%E5%8A%9F%E5%A4%AB%E5%AE%89%E8%A3%85/"/>
    <id>http://www.bookmounting.com/15/功夫安装/</id>
    <published>2019-07-15T02:28:47.000Z</published>
    <updated>2019-07-16T00:52:13.272Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基础环境"><a href="#基础环境" class="headerlink" title="基础环境"></a>基础环境</h2><p>Centos 7</p><p>gcc 7.2+ 要支持C++17</p><p>cmake (&gt;3.12)</p><p>python 2.7</p><p>pip</p><p>git</p><p>Node.js (&gt;=8 &lt;11)</p><p>npm</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#yum -y install centos-release-scl</span><br><span class="line">#yum -y install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-binutils</span><br><span class="line">#echo &quot;source /opt/rh/devtoolset-7/enable&quot; &gt;&gt; /etc/profile</span><br><span class="line">#source /etc/profile</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#npm install -g yarn electron-builder</span><br><span class="line">#pip install pipenv</span><br></pre></td></tr></table></figure><p>设置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PATH=$HOME/bin:/opt/nodejs/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin</span><br></pre></td></tr></table></figure><p>设置镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ npm config set registry https://registry.npm.taobao.org</span><br><span class="line">$ npm config set electron_mirror https://npm.taobao.org/mirrors/electron/</span><br><span class="line">$ npm config set PUPPETEER_DOWNLOAD_HOST https://npm.taobao.org/mirrors</span><br><span class="line">$ npm config set puppeteer_download_host https://npm.taobao.org/mirrors</span><br><span class="line">$ npm config set sass-binary-site http://npm.taobao.org/mirrors/node-sass</span><br></pre></td></tr></table></figure><h2 id="Compile"><a href="#Compile" class="headerlink" title="Compile"></a>Compile</h2><p><strong>常规操作</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/taurusai/kungfu</span><br><span class="line">$ cd kungfu</span><br><span class="line">$ yarn install</span><br><span class="line">$ yarn workspaces run build</span><br></pre></td></tr></table></figure><p>遇到编译问题需要完整的重新编译时，执行以下命令清理临时文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yarn workspaces run clean</span><br></pre></td></tr></table></figure><p><strong>编译模式</strong></p><p>功夫默认编译为 Release 模式（-D<a href="https://cmake.org/cmake/help/v3.12/variable/CMAKE_BUILD_TYPE.html" target="_blank" rel="noopener">CMAKE_BUILD_TYPE</a>=”Release”)，如果希望以 Debug 模式编译，需要执行以下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm config set kungfu-core:cmakejsopt &quot;debug&quot;</span><br></pre></td></tr></table></figure><p>执行以下命令恢复 Release 模式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm config delete kungfu-core:cmakejsopt</span><br></pre></td></tr></table></figure><p>更多可选设置请参考 <a href="https://www.npmjs.com/package/cmake-js" target="_blank" rel="noopener">CMake.js Options</a>。</p><p>切换编译模式后，需要执行以下命令重新生成配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yarn workspace kungfu-core run config</span><br></pre></td></tr></table></figure><p><strong>选择 Python 版本</strong></p><p>功夫支持 Python 2 及 Python 3，在系统预装了相应版本的情况下，编译时可以自行选择所需的 Python 版本。<br>执行以下命令选择 Python 3：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm config set kungfu-core:pyver three</span><br></pre></td></tr></table></figure><p>执行以下命令选择 Python 2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ npm config set kungfu-core:pyver two</span><br></pre></td></tr></table></figure><p>切换 Python 版本后，需要执行以下命令重新生成配置文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yarn workspace kungfu-core run config</span><br></pre></td></tr></table></figure><p><strong>编译过程产生的临时文件</strong></p><p>编译过程会在代码所在目录下生成如下临时文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node_modules</span><br><span class="line">build</span><br><span class="line">dist</span><br></pre></td></tr></table></figure><p>通常情况下可通过执行如下命令对 build 和 dist 进行清理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yarn workspaces run clean</span><br></pre></td></tr></table></figure><p>需要注意 node_modules 目录为 npm 产生的包目录，一般情况下无需清除，如有特殊需要可手动删除。</p><p>另外，编译过程中会在系统的以下路径产生输出：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$HOME/.cmake-js                     # cmake.js 存储的 C++ 依赖包</span><br><span class="line">$HOME/.virtualenvs                  # pipenv(windows) 存储的 Python 依赖</span><br><span class="line">$HOME/.local/share/virtualenvs      # pipenv(unix) 存储的 Python 依赖</span><br></pre></td></tr></table></figure><p>如果需要清理这些文件，都需要手动删除。</p><p><strong>编译时遇到的问题</strong></p><p>1.已经安装anaconda，yarn install失败？</p><p>删除anaconda，rm -rf anaconda*</p><p>2.error Couldn’t find package “pm2@^3.5.0” required by “<a href="mailto:kungfu@2.0.0" target="_blank" rel="noopener">kungfu@2.0.0</a>“ on the “npm” registry</p><p>$ npm config set registry <a href="https://registry.npm.taobao.org" target="_blank" rel="noopener">https://registry.npm.taobao.org</a></p><p>3.error /root/kungfu/node_modules/kungfu-core: Command failed.<br>Exit code: 127<br>Command: echo postinstall at $(pwd) &amp;&amp; pipenv install &amp;&amp; yarn run config:cmake</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;基础环境&quot;&gt;&lt;a href=&quot;#基础环境&quot; class=&quot;headerlink&quot; title=&quot;基础环境&quot;&gt;&lt;/a&gt;基础环境&lt;/h2&gt;&lt;p&gt;Centos 7&lt;/p&gt;
&lt;p&gt;gcc 7.2+ 要支持C++17&lt;/p&gt;
&lt;p&gt;cmake (&amp;gt;3.12)&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="kungfu" scheme="http://www.bookmounting.com/tags/kungfu/"/>
    
  </entry>
  
  <entry>
    <title>引用网页</title>
    <link href="http://www.bookmounting.com/12/%E5%BC%95%E7%94%A8%E7%BD%91%E9%A1%B5/"/>
    <id>http://www.bookmounting.com/12/引用网页/</id>
    <published>2019-07-12T02:20:35.000Z</published>
    <updated>2019-08-01T00:55:47.128Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/sinat_37781304/article/details/82729029" target="_blank" rel="noopener">hexo史上最全搭建教程</a></p><p><a href="https://www.cnblogs.com/sniperHW/p/4172248.html" target="_blank" rel="noopener">基于数组无锁队列</a></p><p><a href="http://moodycamel.com/blog/2014/a-fast-general-purpose-lock-free-queue-for-c++" target="_blank" rel="noopener">块式链表无锁队列</a></p><p><a href="https://www.cnblogs.com/FateTHarlaown/p/8919235.html" target="_blank" rel="noopener">C++11的原子量与内存序浅析</a></p><p><a href="https://www.huihut.com/interview/#/" target="_blank" rel="noopener">C++ 基础</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzU4NDk0ODgyNw==&mid=2247483735&idx=1&sn=4c2c6f31984c7c9be256ff557bd549ce&chksm=fd934c63cae4c5757d33d410d2121317e3bbda9c334d106ca765934b1f2738d98d88c7d5ffc4&mpshare=1&scene=23&srcid=&sharer_sharetime=1564569573222&sharer_shareid=df1921959648bda709ead35f69e3bad9#rd" target="_blank" rel="noopener">内存模型</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/sinat_37781304/article/details/82729029&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;hexo史上最全搭建教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;h
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>LockFree-简单数组无锁队列</title>
    <link href="http://www.bookmounting.com/12/LockFree-%E7%AE%80%E5%8D%95%E6%95%B0%E7%BB%84%E6%97%A0%E9%94%81%E9%98%9F%E5%88%97/"/>
    <id>http://www.bookmounting.com/12/LockFree-简单数组无锁队列/</id>
    <published>2019-07-12T01:42:04.000Z</published>
    <updated>2019-07-16T00:54:32.164Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>支持SPSC（单生产者单消费者）的无锁队列。基于数组实现，避免了多线程中的内存动态分配。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>利用C++ 11的原子量实现原子操作和CAS。</p><p>writeIndex:新元素入列时存放位置在数组中的下标。</p><p>readIndex:下一个出列元素在数组中的下标。</p><p>当readIndex小于writeIndex时，可读。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>ArrayLockFreeQueue.h</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _ARRAYLOCKFREEQUEUE_H___</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _ARRAYLOCKFREEQUEUE_H___</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;atomic&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> QUEUE_INT unsigned long</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ARRAY_LOCK_FREE_Q_DEFAULT_SIZE 65535 <span class="comment">// 2^16</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ELEM_T, QUEUE_INT Q_SIZE = ARRAY_LOCK_FREE_Q_DEFAULT_SIZE&gt;</span><br><span class="line">class ArrayLockFreeQueue</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">ArrayLockFreeQueue();</span><br><span class="line"><span class="keyword">virtual</span> ~ArrayLockFreeQueue();</span><br><span class="line"></span><br><span class="line"><span class="function">QUEUE_INT <span class="title">size</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">enqueue</span><span class="params">(<span class="keyword">const</span> ELEM_T &amp;a_data)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">dequeue</span><span class="params">(ELEM_T &amp;a_data)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">bool</span> <span class="title">try_dequeue</span><span class="params">(ELEM_T &amp;a_data)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line"></span><br><span class="line">ELEM_T m_thequeue[Q_SIZE];</span><br><span class="line"></span><br><span class="line"><span class="keyword">atomic_ulong</span> m_writeIndex;</span><br><span class="line"></span><br><span class="line"><span class="keyword">atomic_ulong</span> m_readIndex;</span><br><span class="line"></span><br><span class="line"><span class="keyword">atomic_ulong</span> m_maximumReadIndex;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> QUEUE_INT <span class="title">countToIndex</span><span class="params">(QUEUE_INT a_count)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ArrayLockFreeQueueImp.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>ArrayLockFreeQueueImp.h</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _ARRAYLOCKFREEQUEUEIMP_H___</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _ARRAYLOCKFREEQUEUEIMP_H___</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"ArrayLockFreeQueue.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ELEM_T, QUEUE_INT Q_SIZE&gt;</span><br><span class="line">ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::ArrayLockFreeQueue() :</span><br><span class="line">m_writeIndex(<span class="number">0</span>),</span><br><span class="line">m_readIndex(<span class="number">0</span>),</span><br><span class="line">m_maximumReadIndex(<span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ELEM_T, QUEUE_INT Q_SIZE&gt;</span><br><span class="line">ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::~ArrayLockFreeQueue()</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ELEM_T, QUEUE_INT Q_SIZE&gt;</span><br><span class="line"><span class="keyword">inline</span> QUEUE_INT ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::countToIndex(QUEUE_INT a_count)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span> (a_count % Q_SIZE);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ELEM_T, QUEUE_INT Q_SIZE&gt;</span><br><span class="line">QUEUE_INT ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::size()</span><br><span class="line">&#123;</span><br><span class="line">QUEUE_INT currentWriteIndex = m_writeIndex;</span><br><span class="line">QUEUE_INT currentReadIndex = m_readIndex;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (currentWriteIndex &gt;= currentReadIndex)</span><br><span class="line"><span class="keyword">return</span> currentWriteIndex - currentReadIndex;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"><span class="keyword">return</span> Q_SIZE + currentWriteIndex - currentReadIndex;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ELEM_T, QUEUE_INT Q_SIZE&gt;</span><br><span class="line"><span class="keyword">bool</span> ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::enqueue(<span class="keyword">const</span> ELEM_T &amp;a_data)</span><br><span class="line">&#123;</span><br><span class="line">QUEUE_INT currentWriteIndex;</span><br><span class="line"><span class="comment">//QUEUE_INT currentReadIndex;</span></span><br><span class="line"></span><br><span class="line">currentWriteIndex = m_writeIndex;</span><br><span class="line"><span class="comment">//currentReadIndex = m_readIndex;</span></span><br><span class="line"></span><br><span class="line">m_thequeue[countToIndex(currentWriteIndex)] = a_data;</span><br><span class="line">m_writeIndex++;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ELEM_T, QUEUE_INT Q_SIZE&gt;</span><br><span class="line"><span class="keyword">bool</span> ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::try_dequeue(ELEM_T &amp;a_data)</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span> dequeue(a_data);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> ELEM_T, QUEUE_INT Q_SIZE&gt;</span><br><span class="line"><span class="keyword">bool</span> ArrayLockFreeQueue&lt;ELEM_T, Q_SIZE&gt;::dequeue(ELEM_T &amp;a_data)</span><br><span class="line">&#123;</span><br><span class="line">QUEUE_INT currentMaximumReadIndex;</span><br><span class="line">QUEUE_INT currentReadIndex;</span><br><span class="line"><span class="comment">//只支持一写一读，多读时单个线程不能读到队列的所有数</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">&#123;</span><br><span class="line">currentReadIndex = m_readIndex;</span><br><span class="line">currentMaximumReadIndex = m_writeIndex;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (countToIndex(currentReadIndex) == countToIndex(currentMaximumReadIndex))</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">a_data = m_thequeue[countToIndex(currentReadIndex)];</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (m_readIndex.compare_exchange_weak(currentReadIndex, (currentReadIndex + <span class="number">1</span>)))</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125; <span class="keyword">while</span> (<span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;支持SPSC（单生产者单消费者）的无锁队列。基于数组实现，避免了多线程中的内存动态分配。&lt;/p&gt;
&lt;h2 id=&quot;原理&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
    
      <category term="C++,LockFree" scheme="http://www.bookmounting.com/tags/C-LockFree/"/>
    
  </entry>
  
</feed>
